{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, IterableDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LEN=20\n",
    "# D_HID_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda(tensor):\n",
    "    if T.cuda.is_available():\n",
    "        tensor = tensor.cuda(0)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Embedding(nn.Module):\n",
    "    def __init__ (self, inputDimSize, embSize):\n",
    "        super(Custom_Embedding, self).__init__()\n",
    "        self.inputDimSize = inputDimSize\n",
    "        self.embSize = embSize\n",
    "        \n",
    "        self.W_emb = nn.Parameter(torch.randn(self.inputDimSize, self.embSize) * 0.01)\n",
    "        self.b_emb = nn.Parameter(torch.zeros(self.embSize) * 0.01) \n",
    "       \n",
    "    def forward(self, x):\n",
    "        #x=x.cuda(0)\n",
    "        return torch.tanh(x@self.W_emb + self.b_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' C-RNN-GAN generator\n",
    "    '''\n",
    "    def __init__(self, input_dim, drug_dim, age_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # params\n",
    "        self.visitEmbedding = Custom_Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.drugEmbedding = Custom_Embedding(drug_dim, emb_dim)\n",
    "        \n",
    "        self.ageEmbedding = Custom_Embedding(age_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    \n",
    "    def forward(self, src, drug, age):\n",
    "        ''' Forward prop\n",
    "        '''\n",
    "        #src=src.cuda(0)\n",
    "        #age=age.cuda(0)\n",
    "#         print(\"==============Inside Encoder=============\")\n",
    "        #src = [batch_size, seq_len, num_feats]\n",
    "        batch_size=src.shape[0]\n",
    "        seq_len=src.shape[1]\n",
    "        #print(\"src\",src.shape)\n",
    "        src = src.view(-1, src.size(2)) # (N*seq_len, num_feats)\n",
    "        #print(\"src\",src.shape)\n",
    "        #src=src.double()\n",
    "        visitEmbedded = self.visitEmbedding(src)\n",
    "\n",
    "        visitEmbedded = visitEmbedded.view(batch_size,seq_len, -1)\n",
    "#         print(\"visitEmbedded\",visitEmbedded.shape)\n",
    "#         print(\"visitEmbedded\",visitEmbedded[0:2,:])\n",
    "#         visitEmbedded = visitEmbedded.view(*src_size, -1)\n",
    "        #print(\"visitEmbedded\",visitEmbedded.shape)\n",
    "#         #print(\"listEmbedding\",list(self.visitEmbedding.parameters()))\n",
    "#         #print(\"visitEmbedded\",visitEmbedded[0,0,:,:])\n",
    "#         #print(\"visitEmbedded\",visitEmbedded[0,0,0,:])\n",
    "#         visitEmbedded = visitEmbedded.sum(2)\n",
    "#         #print(\"visitEmbedded\",visitEmbedded.shape)\n",
    "#         #print(\"visitEmbedded\",visitEmbedded[0,0,:])\n",
    "        \n",
    "        #####DRUG EMBEDDING############\n",
    "        batch_size=drug.shape[0]\n",
    "        seq_len=drug.shape[1]\n",
    "        drug = drug.view(-1, drug.size(2)) # (N*seq_len, num_feats)\n",
    "        #print(\"drug\",drug.shape)\n",
    "        drugEmbedded = self.drugEmbedding(drug)\n",
    "        drugEmbedded = drugEmbedded.view(batch_size,seq_len, -1)\n",
    "        \n",
    "        \n",
    "        batch_size=age.shape[0]\n",
    "        seq_len=age.shape[1]\n",
    "        age = age.view(-1, age.size(2))\n",
    "#         print(\"encoder age\",age.shape)\n",
    "#         #print(\"listEmbedding\",list(self.ageEmbedding.parameters()))\n",
    "#         age = age.view(-1, age.size(2)) # (N*seq_len, num_feats)\n",
    "#         age=age.squeeze()\n",
    "#         print(\"age\",age.shape)\n",
    "        ageEmbedded = self.ageEmbedding(age)\n",
    "        ageEmbedded = ageEmbedded.view(batch_size,seq_len, -1)\n",
    "        #print(\"Encoder ageEmbedded\",ageEmbedded.shape)\n",
    "        #ageEmbedded = ageEmbedded.view(*age_size, -1)\n",
    "        ##print(\"ageEmbedded\",ageEmbedded.shape)\n",
    "        #ageEmbedded = ageEmbedded.sum(2)\n",
    "        ##print(\"ageEmbedded\",ageEmbedded.shape)\n",
    "        \n",
    "        embedded = visitEmbedded + ageEmbedded+ drugEmbedded\n",
    "#         print(\"embedded\",embedded.shape)\n",
    "        embedded = self.dropout(embedded)\n",
    "#         print(\"embedded\",embedded.shape)\n",
    "        \n",
    "        #embedded = [batch_size, seq_len, emb dim]\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "#         print(\"hidden\",hidden.shape)\n",
    "        #print(\"outputs\",outputs.shape)        \n",
    "        #outputs = [batch_size, seq_len, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        ##print(\"hidden\",hidden[-2,:,:].shape)\n",
    "        ##print(\"hidden\",hidden[-1,:,:].shape)\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]. \n",
    "        #hidden is last visit representation\n",
    "        #outputs are always from the last layer. outputs are given at each GRU cell\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        #print(\"hidden\",hidden.shape)\n",
    "        #hidden=hidden.cuda(0)\n",
    "        hidden = self.fc(hidden)\n",
    "#         print(\"hidden\",hidden.shape)\n",
    "        hidden = torch.tanh(hidden)\n",
    "        #print(\"hidden\",hidden.shape)\n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden\n",
    "    def printWeights(self):\n",
    "        print(\"printing encoder weights\")\n",
    "#         print(\"Enc RNN: \",self.rnn.weight.grad)\n",
    "#         print(\"Enc FC: \",self.fc.weight.grad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        #print(\"=====================inside attention======================\")\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        #print(\"hidden\",hidden.shape)\n",
    "        #print(\"encoder_outputs\",encoder_outputs.shape)\n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        #print(\"energy\",energy.shape)\n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        #print(\"attention\",attention.shape)\n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, age_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.visitEmbedding = Custom_Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.ageEmbedding = Custom_Embedding(age_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, age, hidden, encoder_outputs):\n",
    "             \n",
    "        #print(\"================Inside Decoder===============\")\n",
    "        #print(\"input\",input.shape)\n",
    "        #print(\"age\",age.shape)\n",
    "        #print(\"hidden\",hidden.shape)\n",
    "        #print(\"encoder_outputs\",encoder_outputs.shape)\n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        #input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        batch_size=input.shape[0]\n",
    "        input=input.float()\n",
    "        visitEmbedded = self.visitEmbedding(input)\n",
    "        #print(\"visitEmbedded\",visitEmbedded.shape)\n",
    "        \n",
    "        \n",
    "        #print(\"age\",age.shape)\n",
    "#         #print(\"listEmbedding\",list(self.ageEmbedding.parameters()))\n",
    "#         age = age.view(-1, age.size(2)) # (N*seq_len, num_feats)\n",
    "#         age=age.squeeze()\n",
    "#         print(\"age\",age.shape)\n",
    "        ageEmbedded = self.ageEmbedding(age)\n",
    "        #print(\"ageEmbedded\",ageEmbedded.shape)\n",
    "        #ageEmbedded = ageEmbedded.view(batch_size,seq_len, -1)\n",
    "        \n",
    "        \n",
    "        embedded = visitEmbedded + ageEmbedded\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded=embedded.unsqueeze(0)\n",
    "        #print(\"embedded\",embedded.shape)\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)        \n",
    "        #print(\"out of attention\")\n",
    "        #a = [batch size, src len]\n",
    "        #print(\"a\",a.shape)\n",
    "        a = a.unsqueeze(1)\n",
    "        #print(\"a\",a.shape)\n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        #encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #print(\"encoder_outputs\",encoder_outputs.shape)\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        #print(\"weighted\",weighted.shape)\n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        #weighted=weighted.squeeze()\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        #print(\"weighted\",weighted.shape)\n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        #print(\"embedded\",embedded.shape)\n",
    "        #print(\"hidden\",hidden.shape)    \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        #print(\"rnn_input\",rnn_input.shape)\n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        #print(\"output\",output.shape) \n",
    "        #print(\"hidden\",hidden.shape) \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        #print(\"embedded\",embedded.shape)\n",
    "        #print(\"output\",output.shape) \n",
    "        #print(\"weighted\",weighted.shape)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        #print(\"prediction\",prediction .shape)\n",
    "        ##print(\"prediction\",prediction)\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0),a.squeeze(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, drug, trg, age, mask, train, train_on_gpu):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [trg len, batch size, trg_features]\n",
    "        trg=trg.permute(1,0,2)\n",
    "        #print(\"trg\",trg.shape)\n",
    "        #print(\"===========Inside seq2seq===========\")\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_features = self.decoder.output_dim\n",
    "        \n",
    "        #print(\"batch_size\",batch_size)\n",
    "        #print(\"trg_len\",trg_len)\n",
    "        #print(\"trg_features\",trg_features)\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        if train_on_gpu:\n",
    "            outputs = torch.zeros(trg_len, batch_size, trg_features).cuda(0)\n",
    "            attn = torch.zeros(trg_len, batch_size, trg_len).cuda(0)\n",
    "        else:\n",
    "            outputs = torch.zeros(trg_len, batch_size, trg_features)\n",
    "            attn = torch.zeros(trg_len, batch_size, trg_len)\n",
    "            \n",
    "        #print(\"outputs\",outputs.shape)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        #print(\"Age\",age.shape)\n",
    "        encoder_outputs, hidden = self.encoder(src, drug, age)\n",
    "        #print(\"===========Outside Encoder===========\")\n",
    "        \n",
    "        #print(\"encoder_outputs\",encoder_outputs.shape)\n",
    "        #print(\"hidden\",hidden.shape)\n",
    "        \n",
    "        #print(\"===========Preparing input for Decoder===========\")\n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = torch.zeros(batch_size, trg_features, dtype=T.long)#trg[0,:]\n",
    "        #print(\"input\",input.shape)\n",
    "        age=age.squeeze()\n",
    "        #print(\"age\",age.shape)\n",
    "        #print(age)\n",
    "        age=age.permute(1,0)\n",
    "        #print(\"age\",age.shape)\n",
    "        #inputAge = age[0]#torch.zeros(batch_size, dtype=T.long)\n",
    "        \n",
    "        mask=mask.permute(1,0)\n",
    "        \n",
    "        for t in range(0, trg_len):\n",
    "            #print(\"=================Inside for loop================\")\n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            inputAge=age[t]\n",
    "            inputAge=inputAge.unsqueeze(1)\n",
    "            #print(\"age\",inputAge.shape)\n",
    "            output, hidden,a = self.decoder(input, inputAge, hidden, encoder_outputs)\n",
    "            #print(\"==============Outside decoder=================\")\n",
    "            #print(\"output\",output.shape)\n",
    "            #print(\"hidden\",hidden.shape)\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            attn[t] = a\n",
    "            #print(\"OUTPUTS\",outputs.shape)\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            #print(\"top1\",top1.shape)\n",
    "            ##print(\"top1\",top1[0:2])\n",
    "            \n",
    "            ##print(\"age\",inputAge)\n",
    "            #print(\"======Deciding next input for decoder=========\")\n",
    "            prediction = F.one_hot(top1, num_classes=trg_features)\n",
    "            #print(\"prediction\",prediction.shape)\n",
    "            ##print(\"prediction\",prediction[0:2,:])\n",
    "            #print(\"mask\",mask.shape)\n",
    "            ##print(\"mask\",mask[t])\n",
    "            ##print(\"mask\",mask[t].unsqueeze(1).repeat(1,trg_features))\n",
    "            inputMask=mask[t]\n",
    "            #print(\"inputMask\",inputMask.shape)\n",
    "            #inputMask[1]=1\n",
    "            inputMask=inputMask.unsqueeze(1).repeat(1,trg_features)\n",
    "            #print(\"inputMask\",inputMask.shape)\n",
    "            #print(\"trg\",trg[t].shape)\n",
    "            ##print(\"inputMask\",inputMask[0:2,:])\n",
    "            inputMask=inputMask.float()\n",
    "            trg[t]=trg[t].float()\n",
    "            prediction=prediction.float()\n",
    "            context=trg[t] * inputMask + prediction * (1-inputMask)\n",
    "            #print(\"context\",context.shape)\n",
    "            \n",
    "            ##print(\"inputMask\",inputMask[0:2,:])\n",
    "            ##print(\"trg\",trg[t,0:2,:])\n",
    "            ##print(\"prediction\",prediction[0:2,:])\n",
    "            ##print(\"context\",context[0:2,:])\n",
    "\n",
    "            if train:\n",
    "                #print(\"=========Training===========\")\n",
    "                input = context\n",
    "            else:\n",
    "                #print(\"===========Testing==========\")\n",
    "                input = prediction\n",
    "            #print(\"Next input for decoder\",input.shape)\n",
    "        #print(\"Final output\",outputs.shape)\n",
    "        return outputs, attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, MAX_SEQ_LEN, D_HID_SIZE):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.SEQ_LEN = MAX_SEQ_LEN\n",
    "        self.D_HID_SIZE = D_HID_SIZE\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.rnn_cell = nn.LSTMCell(1, self.D_HID_SIZE)\n",
    "        self.regression1 = nn.Linear(self.D_HID_SIZE, 5)\n",
    "        self.leaky = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.regression2 = nn.Linear(5, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def merge_score(self, score_f):\n",
    "        \n",
    "        #print(\"Foward Scores\",score_f['scores'][0,:])\n",
    "        #print(\"Backward Scores\",score_b['scores'][0,:])\n",
    "        #print(\"Missing\",score_f['missing'][0,:])\n",
    "        #print(\"Foward Scores\",score_f['scores'].size())\n",
    "        #print(\"Backward Scores\",score_b['scores'].size())\n",
    "        #print(\"Missing\",score_f['missing'].size())\n",
    "        \n",
    "        #Calculate Loss for Sigmid layer\n",
    "        Tensor = torch.cuda.FloatTensor\n",
    "        \n",
    "        score_f['scoresSig'] = torch.flatten(score_f['scoresSig'])\n",
    "        score_f['missing'] = torch.flatten(score_f['missing'])\n",
    "        \n",
    "        \n",
    "        real_ids = (score_f['missing'].nonzero())\n",
    "        fake_ids = ((1-score_f['missing']).nonzero())\n",
    "        \n",
    "        # Loss function\n",
    "        adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable((score_f['missing'])[real_ids], requires_grad=False)\n",
    "        fake = Variable((score_f['missing'])[fake_ids], requires_grad=False)\n",
    "        validG = Variable((1-score_f['missing'])[fake_ids], requires_grad=False)\n",
    "        \n",
    "        #print(\"Valid\",valid.size())\n",
    "        #print(\"fake\",fake.size())\n",
    "               \n",
    "        #ret_b['scores'] = ret_b['scores'] * ret_b['missing']\n",
    "        #print(\"Final Scores\",ret_b['imputations'][0,:])\n",
    "                \n",
    "        if(fake_ids.size()[0]==0 ):     \n",
    "            loss_gSig=Variable(torch.cuda.FloatTensor([0]), requires_grad=True)\n",
    "        else:\n",
    "            loss_gF = adversarial_loss((score_f['scoresSig'])[fake_ids], validG)\n",
    "            loss_gSig=loss_gF\n",
    "        \n",
    "        loss_dReal = adversarial_loss((score_f['scoresSig'])[real_ids], valid)\n",
    "        if(fake_ids.size()[0]==0 ): \n",
    "            loss_dSig = loss_dReal\n",
    "        else:\n",
    "            loss_dFake = adversarial_loss((score_f['scoresSig'])[fake_ids], fake)\n",
    "            loss_dSig = (loss_dReal + loss_dFake)/2\n",
    "        #print(loss_dSig,loss_gSig)\n",
    "        return {'loss_d': loss_dSig , 'loss_g': loss_gSig}\n",
    "        \n",
    "    def forward(self, values, masks, direct):\n",
    "        \n",
    "        h = Variable(torch.zeros((values.size()[0], self.D_HID_SIZE)))\n",
    "        c = Variable(torch.zeros((values.size()[0], self.D_HID_SIZE)))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            h, c = h.cuda(0), c.cuda(0)\n",
    "            values, masks = values.cuda(0), masks.cuda(0)\n",
    "            \n",
    "        scoresSig=[]\n",
    "        missing=[]\n",
    "        if(direct==\"forward\"):\n",
    "\n",
    "            for t in range(self.SEQ_LEN):\n",
    "                #print(\"===============\",t,\"======================\")\n",
    "                x = values[:, t]\n",
    "                x=x.unsqueeze(dim=1)\n",
    "                m = masks[:, t]\n",
    "                #print(\"Input\",x.size())\n",
    "                #print(\"Input\",x[0])\n",
    "\n",
    "                x_h = self.regression1(h)\n",
    "                x_h = self.leaky(x_h)\n",
    "                x_h = self.regression2(x_h)\n",
    "                x_h2 = self.sig(x_h)\n",
    "                #print(\"Discriminator output\",x_h[0])\n",
    "                #print(\"Discriminator output\",x_h2[0])\n",
    "\n",
    "                #print(\"Output regression\",x_h.size())\n",
    "                #print(\"Mask\",m.size())\n",
    "\n",
    "                m=m.unsqueeze(dim=1)\n",
    "                \n",
    "                #print(\"i am here\")\n",
    "\n",
    "                h, c = self.rnn_cell(x, (h, c))\n",
    "                #print(\"i am here\")\n",
    "\n",
    "                #imputations.append(x_c[:,316].unsqueeze(dim = 1))\n",
    "                scoresSig.append(x_h2[:,0].unsqueeze(dim = 1))\n",
    "                #print(\"i am here\")\n",
    "                missing.append(m)\n",
    "                #print(\"i am here\")\n",
    "                #print(\"to be appended\",m.size())\n",
    "                #print(\"Imputations\",len(imputations))\n",
    "                #print(\"Scores\",scores[0].size())\n",
    "        \n",
    "        elif(direct==\"backward\"):\n",
    "\n",
    "            for t in range(self.SEQ_LEN-1,-1,-1):\n",
    "                #print(\"===============\",t,\"======================\")\n",
    "                x = values[:, t]\n",
    "                x=x.unsqueeze(dim=1)\n",
    "                m = masks[:, t]\n",
    "                #print(\"Input\",x.size())\n",
    "                #print(\"Input\",x[0])\n",
    "\n",
    "                x_h = self.regression1(h)\n",
    "                x_h = self.leaky(x_h)\n",
    "                x_h = self.regression2(x_h)\n",
    "                x_h2 = self.sig(x_h)\n",
    "                #print(\"Discriminator output\",x_h.shape)\n",
    "\n",
    "                #print(\"Output regression\",x_h.size())\n",
    "                #print(\"Mask\",m.size())\n",
    "\n",
    "                m=m.unsqueeze(dim=1)\n",
    "                \n",
    "                #print(\"d\",d[:,0].unsqueeze(dim=1).size())\n",
    "\n",
    "                h, c = self.rnn_cell(x, (h, c))\n",
    "\n",
    "                #imputations.append(x_c[:,316].unsqueeze(dim = 1))\n",
    "                scoresSig.append(x_h2[:,0].unsqueeze(dim = 1))\n",
    "                missing.append(m)\n",
    "                #print(\"to be appended\",m.size())\n",
    "                #print(\"Imputations\",len(imputations))\n",
    "                #print(\"Scores\",scores[0].size())\n",
    "        \n",
    "        scoresSig = torch.cat(scoresSig, dim = 1)\n",
    "        missing = torch.cat(missing, dim = 1)\n",
    "        #print(\"Scores\",len(scores),scores[0].size())\n",
    "        return self.merge_score({'scoresSig': scoresSig, 'missing':missing})\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path, chunksize,length,seq_len,flag):\n",
    "        self.path = path\n",
    "        self.chunksize = chunksize\n",
    "        self.len = int(length)#number of times total getitem is called\n",
    "        self.seq_len=seq_len\n",
    "        self.flag=flag\n",
    "        self.reader=pd.read_csv(\n",
    "                self.path,header=0,\n",
    "                chunksize=self.chunksize)#,names=['data']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.reader.get_chunk(self.chunksize)\n",
    "        #sex=pd.read_csv('C:\\\\Users/mehak/Desktop/demo.csv',header=0)\n",
    "        #sex=sex[['person_id','Sex']]\n",
    "        #data = pd.merge(data, sex, how='left', on=['person_id'])\n",
    "        #print(data.shape)\n",
    "        #data=data.sort_values(by=['RANDOM_PATIENT_ID','VISIT_YEAR','VISIT_MONTH'])\n",
    "        #print(data['RANDOM_PATIENT_ID'].unique())\n",
    "#         del data['person_id']\n",
    "#         print(data.columns.get_loc('BMI'))\n",
    "        #print(data.columns)\n",
    "\n",
    "        data=data.replace(np.inf,0)\n",
    "        data=data.replace(np.nan,0)\n",
    "        data=data.fillna(0)\n",
    "        #print(data.shape)\n",
    "        if(self.flag==0):\n",
    "            #data['Age']=data['Age'].apply(lambda x: ((x*12)/3)-81)\n",
    "#             data['Stomach finding']=0\n",
    "            pids=data['person_id']\n",
    "            pids = T.as_tensor(pids.values.astype(float), dtype=T.long)\n",
    "#             print(\"age\",data['Age'])\n",
    "#             print(\"pids\",list(pids))\n",
    "#             print(\"========================================================\")\n",
    "\n",
    "            data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "    #         print(list(data[:,0]))\n",
    "    #         print(\"========================================================\")\n",
    "            #data=T.from_numpy(data)\n",
    "            #data=data.double()\n",
    "            data=data.view(int(data.shape[0]/self.seq_len), self.seq_len, data.shape[1])\n",
    "            #print(data.shape)\n",
    "            return data,pids\n",
    "        elif(self.flag==2):\n",
    "            #data['losartan']=0\n",
    "            data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "            data=data.view(int(data.shape[0]/self.seq_len), self.seq_len, data.shape[1])\n",
    "            return data\n",
    "        else:\n",
    "            data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "            data=data.view(int(data.shape[0]/self.seq_len), self.seq_len, data.shape[1])\n",
    "            \n",
    "            return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, args, patience=7, verbose=False, delta=0):#-0.01\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf#11.1179\n",
    "        self.delta = delta\n",
    "        self.args=args\n",
    "\n",
    "    def __call__(self, val_loss, model, optimizer, save_path):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, optimizer, save_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if score > self.best_score + 0:\n",
    "                self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, optimizer, save_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, optimizer, save_path):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        if  self.args.discriminator:\n",
    "            T.save({\n",
    "                \"G_model\": model['g'].state_dict(),\n",
    "                \"D_model\": model['d'].state_dict(),\n",
    "                'G_trainer': optimizer['g'].state_dict(),\n",
    "                'D_trainer': optimizer['d'].state_dict()\n",
    "            }, save_path)\n",
    "        else:\n",
    "            T.save({\n",
    "                \"G_model\": model['g'].state_dict(),\n",
    "                'G_trainer': optimizer['g'].state_dict()\n",
    "            }, save_path)\n",
    "        self.val_loss_min = -self.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_emb = nn.Parameter(torch.randn(10, 5) * 0.01)\n",
    "#b_emb = nn.Parameter(torch.zeros(5) * 0.01) \n",
    "       \n",
    "    \n",
    "#torch.tanh(x@self.W_emb + self.b_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-6.0893e-03, -1.2221e-02, -1.9950e-04, -6.2818e-03,  8.7840e-04],\n",
       "        [ 1.6809e-02,  2.4981e-02, -2.9280e-03, -2.9692e-03, -7.5641e-03],\n",
       "        [ 1.7082e-03,  2.8238e-03, -4.5027e-03, -1.8286e-03, -1.1840e-03],\n",
       "        [ 1.5375e-02,  1.2315e-02,  5.0763e-03,  1.3537e-02, -9.2942e-04],\n",
       "        [ 3.8756e-03, -1.6691e-03,  6.6457e-03, -6.2233e-03, -7.0930e-03],\n",
       "        [ 1.1251e-02,  4.6324e-03, -5.9148e-03,  1.3852e-03,  3.3464e-03],\n",
       "        [-1.5402e-02,  2.3139e-03,  4.3486e-03, -4.2589e-03, -3.6165e-03],\n",
       "        [ 4.7201e-03, -2.8067e-03,  2.9867e-03,  4.7570e-03, -7.5531e-03],\n",
       "        [-1.8638e-02, -1.8305e-03,  4.3261e-03,  7.7344e-03,  7.2551e-03],\n",
       "        [ 1.6162e-04, -2.5067e-03, -1.3397e-02, -7.6573e-05,  1.6650e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=torch.rand((20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9394, 0.2193, 0.5036, 0.6045, 0.2243, 0.8799, 0.5826, 0.5922, 0.2516,\n",
       "         0.1680],\n",
       "        [0.6566, 0.8166, 0.8150, 0.8155, 0.4225, 0.6462, 0.8814, 0.9544, 0.0511,\n",
       "         0.5803],\n",
       "        [0.6730, 0.2475, 0.6231, 0.0054, 0.2907, 0.3123, 0.0914, 0.0269, 0.3092,\n",
       "         0.0061],\n",
       "        [0.8830, 0.0163, 0.2944, 0.0123, 0.6187, 0.7683, 0.4872, 0.0553, 0.7860,\n",
       "         0.7100],\n",
       "        [0.9427, 0.4828, 0.4373, 0.3135, 0.9343, 0.7308, 0.6924, 0.0260, 0.3376,\n",
       "         0.7189],\n",
       "        [0.6380, 0.6036, 0.2492, 0.2471, 0.7153, 0.2933, 0.0039, 0.9437, 0.6519,\n",
       "         0.5304],\n",
       "        [0.3565, 0.2318, 0.4736, 0.3471, 0.6950, 0.9692, 0.3261, 0.4120, 0.5497,\n",
       "         0.4465],\n",
       "        [0.7704, 0.6597, 0.7404, 0.9754, 0.1743, 0.2654, 0.2726, 0.9924, 0.6058,\n",
       "         0.5487],\n",
       "        [0.0354, 0.7807, 0.3702, 0.8434, 0.8027, 0.5034, 0.9833, 0.3385, 0.6894,\n",
       "         0.6097],\n",
       "        [0.0886, 0.4313, 0.6243, 0.8636, 0.5273, 0.6590, 0.0606, 0.9589, 0.7804,\n",
       "         0.4070],\n",
       "        [0.2687, 0.7184, 0.0062, 0.0828, 0.9826, 0.6594, 0.3766, 0.4083, 0.7514,\n",
       "         0.5842],\n",
       "        [0.4554, 0.1030, 0.6406, 0.9442, 0.1250, 0.9364, 0.4776, 0.1373, 0.7877,\n",
       "         0.7818],\n",
       "        [0.9824, 0.9393, 0.7557, 0.5853, 0.3701, 0.0900, 0.2814, 0.4767, 0.3745,\n",
       "         0.3133],\n",
       "        [0.9496, 0.2074, 0.1701, 0.1424, 0.2275, 0.9539, 0.7277, 0.8912, 0.8711,\n",
       "         0.7517],\n",
       "        [0.1171, 0.0634, 0.0144, 0.9200, 0.2387, 0.7989, 0.1264, 0.4075, 0.3066,\n",
       "         0.8225],\n",
       "        [0.4369, 0.6052, 0.0476, 0.9216, 0.5190, 0.5726, 0.5186, 0.1718, 0.5217,\n",
       "         0.2753],\n",
       "        [0.1075, 0.8025, 0.7425, 0.4713, 0.0231, 0.8810, 0.6786, 0.5056, 0.9550,\n",
       "         0.7289],\n",
       "        [0.5154, 0.6787, 0.9762, 0.7968, 0.7133, 0.1124, 0.9572, 0.4380, 0.1374,\n",
       "         0.9917],\n",
       "        [0.0159, 0.3214, 0.5827, 0.4675, 0.4922, 0.2791, 0.9518, 0.9596, 0.6112,\n",
       "         0.4943],\n",
       "        [0.6509, 0.6741, 0.0192, 0.9217, 0.9897, 0.3933, 0.5278, 0.0952, 0.8665,\n",
       "         0.7451]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0080,  0.0054, -0.0006,  0.0028, -0.0026],\n",
       "        [ 0.0226,  0.0248, -0.0039,  0.0024, -0.0085],\n",
       "        [-0.0012,  0.0003, -0.0018, -0.0053, -0.0012],\n",
       "        [-0.0151, -0.0091, -0.0057, -0.0045,  0.0138],\n",
       "        [ 0.0031,  0.0066, -0.0052, -0.0090,  0.0039],\n",
       "        [ 0.0089,  0.0060, -0.0002,  0.0025, -0.0022],\n",
       "        [ 0.0082,  0.0078, -0.0032,  0.0027,  0.0031],\n",
       "        [ 0.0156,  0.0175, -0.0015,  0.0125, -0.0014],\n",
       "        [ 0.0090,  0.0300,  0.0028,  0.0066, -0.0021],\n",
       "        [ 0.0196,  0.0193,  0.0009,  0.0167, -0.0013],\n",
       "        [ 0.0052,  0.0140, -0.0009, -0.0018,  0.0007],\n",
       "        [ 0.0043,  0.0119, -0.0078,  0.0136,  0.0162],\n",
       "        [ 0.0135,  0.0184, -0.0014, -0.0007, -0.0067],\n",
       "        [-0.0113, -0.0044, -0.0054,  0.0028,  0.0100],\n",
       "        [ 0.0188,  0.0114, -0.0067,  0.0148,  0.0121],\n",
       "        [ 0.0134,  0.0221,  0.0040,  0.0080, -0.0017],\n",
       "        [ 0.0056,  0.0272, -0.0096,  0.0099,  0.0083],\n",
       "        [ 0.0111,  0.0208, -0.0056, -0.0015, -0.0005],\n",
       "        [-0.0029,  0.0129,  0.0035,  0.0067, -0.0041],\n",
       "        [ 0.0061,  0.0180,  0.0031,  0.0056,  0.0050]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.tanh(x@W_emb + b_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
