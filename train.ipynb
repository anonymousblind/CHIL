{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from oldModel2.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import import_ipynb\n",
    "from model import *\n",
    "import random\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from pickle import dump,load\n",
    "#from helper_functions import *\n",
    "#from dataset import get_data_loader\n",
    "import torchvision.utils as utils\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "from argparse import ArgumentParser\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "save_path = \"data/saved_models/male/pre/disc/full/model3.tar\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# if not os.path.exists(\"data/saved_models\"):\n",
    "#     os.makedirs(\"data/saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--clip_value'], dest='clip_value', nargs=None, const=None, default=0.01, type=<class 'float'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARG_PARSER = ArgumentParser()\n",
    "\n",
    "ARG_PARSER.add_argument('--num_epochs', default=100, type=int)\n",
    "ARG_PARSER.add_argument('--seq_len', default=40, type=int)\n",
    "ARG_PARSER.add_argument('--batch_size', default=100, type=int)\n",
    "ARG_PARSER.add_argument('--patience', default=30, type=int)\n",
    "ARG_PARSER.add_argument('--resume_training', default=False)\n",
    "ARG_PARSER.add_argument('--train', default=True)\n",
    "ARG_PARSER.add_argument('--evalPred', default=False)\n",
    "ARG_PARSER.add_argument('--predWin', default=28, type=int)\n",
    "ARG_PARSER.add_argument('--discriminator', default=True)\n",
    "ARG_PARSER.add_argument('--attn', default=False)\n",
    "ARG_PARSER.add_argument('--female', default=False)\n",
    "ARG_PARSER.add_argument('--male', default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = ARG_PARSER.parse_args(args=[])\n",
    "if ARGS.female:\n",
    "    INPUT_DIM = 1443\n",
    "    GENDER = \"female\"\n",
    "    G = \"F\"\n",
    "if ARGS.male:\n",
    "    INPUT_DIM = 1457\n",
    "    GENDER = \"male\"\n",
    "    G = \"M\"\n",
    "OUTPUT_DIM = 4\n",
    "AGE_DIM = 40\n",
    "DRUG_DIM = 380\n",
    "ENC_EMB_DIM = 256#124\n",
    "DEC_EMB_DIM = 20#50\n",
    "ENC_HID_DIM = 512#256\n",
    "DEC_HID_DIM = 126\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "D_HID_SIZE = 10\n",
    "MAX_SEQ_LEN = ARGS.seq_len\n",
    "BATCH_SIZE = ARGS.batch_size\n",
    "EPSILON = 1e-40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_test(args, model):\n",
    "    model['g'].eval()\n",
    "    \n",
    "    RLoss=0\n",
    "    TBatches=0\n",
    "    oBmi=[]\n",
    "    iBmi=[]\n",
    "    oAge=[]\n",
    "    oPids=[]\n",
    "    oAttn=[]\n",
    "    oAttnIdx=[]\n",
    "\n",
    "    with T.autograd.no_grad():\n",
    "        files = 'data/test/'+GENDER+'/data'+G+'test.csv'\n",
    "        \n",
    "        drugFiles = 'data/test/'+GENDER+'/drug/drug'+G+'test.csv'\n",
    "    \n",
    "        maskFiles = 'data/test/'+GENDER+'/mask/mask'+G+'test.csv'\n",
    "        #print(files)http://localhost:8888/notebooks/Desktop/VAE/BRITS/main.ipynb#\n",
    "        \n",
    "        dataset = CSVDataset(files, int(args.seq_len*BATCH_SIZE),1356100,args.seq_len,flag=0)\n",
    "        drugDataset = CSVDataset(drugFiles, int(args.seq_len*BATCH_SIZE),1356100, args.seq_len,flag=1)\n",
    "        maskDataset = CSVDataset(maskFiles, int(args.seq_len*BATCH_SIZE),1356100, args.seq_len,flag=2)\n",
    "\n",
    "        loader = DataLoader(dataset,batch_size=1,num_workers=0, shuffle=False)#number of times getitem is called in one iteration\n",
    "        drugLoader = DataLoader(drugDataset,batch_size=1,num_workers=0, shuffle=False)\n",
    "        maskLoader = DataLoader(maskDataset,batch_size=1,num_workers=0, shuffle=False)\n",
    "\n",
    "        \n",
    "        loss={}\n",
    "\n",
    "        #for every batch\n",
    "        for batch_idx, allData in enumerate(zip(loader, drugLoader, maskLoader)):\n",
    "            data,drug,mask=allData\n",
    "            pids=data[1]\n",
    "            data=data[0]\n",
    "            if args.male:\n",
    "                age=data[:,:,:,1462]\n",
    "                data=data[:,:,:,1:1458]\n",
    "            elif args.female:\n",
    "                age=data[:,:,:,1448]\n",
    "                data=data[:,:,:,1:1444]\n",
    "            drug=drug[:,:,:,2:382]\n",
    "            target=mask[:,:,:,:4]\n",
    "            mask=mask[:,:,:,4]\n",
    "            \n",
    "#             print(data.shape)\n",
    "#             print(mask.shape)\n",
    "#             print(target.shape)\n",
    "            \n",
    "            age=age.squeeze()\n",
    "            data=data.squeeze()\n",
    "            drug=drug.squeeze()\n",
    "            mask=mask.squeeze()\n",
    "            target=target.squeeze()\n",
    "            pids=pids.squeeze()\n",
    "            pids=pids.view(data.shape[0],data.shape[1])\n",
    "#             print(\"pids\",pids.shape)\n",
    "#             print(\"pids\",pids[0])\n",
    "            testMask = mask.clone().detach()\n",
    "            y = target.clone().detach()\n",
    "            #print(\"ageOutside\",age[0])\n",
    "        \n",
    "             #------------remove last 5 timestamps------------------\n",
    "            #print(data[0:10,8:,653])\n",
    "#             print(\"=====Initial Data===============\")\n",
    "#             #print(\"data\",data[0,0,:])\n",
    "#             print(\"mask\",mask[0])\n",
    "#             print(\"testMask\",testMask[0])\n",
    "            \n",
    "            for i in range(data.shape[0]):\n",
    "                #total length\n",
    "                j=40\n",
    "                #prediction window\n",
    "                k=args.predWin\n",
    "                #remove values from pred window\n",
    "                data[i,j-k:j,:]=0\n",
    "                drug[i,j-k:j,:]=0\n",
    "                mask[i,j-k:j]=0\n",
    "                y[i,j-k:j,:]=0\n",
    "                #zero values in observation window, so that it can be used to check loss in pred win only\n",
    "                target[i,0:j-k,:]=0\n",
    "                testMask[i,0:j-k]=0\n",
    "            \n",
    "#             print(\"=====test Data===============\")\n",
    "#             #print(\"data\",data[0,0,:])\n",
    "#             print(\"mask\",mask[0])\n",
    "#             print(\"testMask\",testMask[0])\n",
    "            \n",
    "#             print(\"=====idxs Data===============\")\n",
    "            #check where obs win is empty\n",
    "            emptyIds=torch.sum(data.reshape(data.shape[0],-1),dim=1)\n",
    "#             print(\"emptyIds\",emptyIds.shape)\n",
    "#             print(\"emptyIds\",emptyIds)\n",
    "            idxs = torch.nonzero(emptyIds > 0)\n",
    "            idxs=idxs.squeeze()\n",
    "#             print(\"idxs\",idxs.shape)\n",
    "            #get only data points that have atleast 1 entry in obs window\n",
    "            data=data[idxs]\n",
    "            drug=drug[idxs]\n",
    "            mask=mask[idxs]\n",
    "            y=y[idxs]\n",
    "            target=target[idxs]\n",
    "            testMask=testMask[idxs]\n",
    "            pids=pids[idxs]\n",
    "            age=age[idxs]\n",
    "            \n",
    "#             print(\"data\",data.shape)\n",
    "#             print(\"drug\",drug.shape)\n",
    "#             print(\"mask\",mask.shape)\n",
    "#             print(\"target\",target.shape)\n",
    "#             print(\"pids\",pids.shape)\n",
    "#             print(\"testMask\",testMask.shape)\n",
    "#             print(\"age\",age.shape)\n",
    "\n",
    "             #------------E training------------------\n",
    "            #data=torch.cat((data,y),2)\n",
    "            data=data.cuda(0)\n",
    "            drug=drug.cuda(0)\n",
    "            target=target.cuda(0)\n",
    "            age=age.cuda(0)\n",
    "            mask=mask.cuda(0)\n",
    "            y=y.cuda(0)\n",
    "            testMask=testMask.cuda(0)\n",
    "            if args.attn:\n",
    "                output,attn = model['g'](data, drug, y, age, mask, args.train)\n",
    "            else:\n",
    "                output = model['g'](data, drug, y, age, mask, args.train)\n",
    "            \n",
    "\n",
    "            #------------R Loss------------------\n",
    "#             print(\"======outputs==============\")\n",
    "#             print(\"output\",output.shape)\n",
    "            \n",
    "            if args.attn:\n",
    "                attn = attn.permute(1,0,2)\n",
    "                attn = attn.reshape(-1,attn.shape[2])\n",
    "                values, indices = torch.topk(attn,k=10,dim=1)\n",
    "\n",
    "            output = output.permute(1,0,2)\n",
    "            #print(\"output\",output.shape)\n",
    "            output = output.reshape(-1,output.shape[2])\n",
    "#             print(\"output\",output.shape)\n",
    "            #print(\"target\",target.shape)\n",
    "            ##print(\"output\",output[0,0,:])\n",
    "            ##print(\"target\",target[0,0,:])\n",
    "            top1 = target.argmax(2)\n",
    "            top1=top1.view(-1)\n",
    "#             print(\"top1\",top1.shape)\n",
    "            \n",
    "\n",
    "            testMask=testMask.view(-1)\n",
    "            #print(\"mask\",mask)\n",
    "            \n",
    "            #idxs are indices where mask is 1 i:e value is present to calculate supervised loss\n",
    "            idxs = torch.nonzero(testMask == 1)\n",
    "#             print(\"idxs\",idxs.shape)\n",
    "            idxs=idxs.squeeze()\n",
    "#             print(\"idxs\",idxs.shape)\n",
    "#             print(\"idxs\",idxs)\n",
    "            #print(\"mask\",mask[idxs])\n",
    "\n",
    "            pids=pids.view(-1)\n",
    "            age=age.view(-1)\n",
    "            output = output[idxs,:]\n",
    "            if args.attn:\n",
    "                values = values[idxs,:]\n",
    "                indices = indices[idxs,:]\n",
    "            top1 = top1[idxs]\n",
    "            age=age[idxs]\n",
    "            pids=pids[idxs]\n",
    "#             print(\"output\",output.shape)\n",
    "#             print(\"top1\",top1.shape)\n",
    "#             print(\"age\",age.shape)\n",
    "#             print(\"pids:\",pids[0])\n",
    "#             print(\"========================================================\")\n",
    "            #print(\"pids\",pids[0])\n",
    "            if args.attn:\n",
    "                values=values.cpu()\n",
    "                indices=indices.cpu()\n",
    "\n",
    "            ##print(\"output\",output)\n",
    "            ##print(\"top1\",top1)\n",
    "            \n",
    "\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            RLoss = RLoss + loss(output, top1)\n",
    "            #print(\"loss\",RLoss)\n",
    "\n",
    "            #Preparing outputs for testing statistics\n",
    "            oBmi.extend(output)\n",
    "            iBmi.extend(top1)\n",
    "            oAge.extend(age)\n",
    "            oPids.extend(pids)\n",
    "            if args.attn:\n",
    "                oAttn.extend(values)\n",
    "                oAttnIdx.extend(indices)\n",
    "            #print(\"oBmi\",len(oBmi))\n",
    "            #print(\"oBmi\",oBmi[0])\n",
    "            #print(\"iBmi\",len(iBmi))\n",
    "            #print(\"oAge\",len(oAge))\n",
    "            #print(\"oPids\",len(oPids))\n",
    "            \n",
    "        TBatches=TBatches+batch_idx+1\n",
    "        RLoss = RLoss/TBatches\n",
    "    \n",
    "    #print(\"===================================\")\n",
    "    #oBmi=np.asarray(oBmi)\n",
    "    #iBmi=np.asarray(iBmi)\n",
    "    #oAge=np.asarray(oAge)\n",
    "    #iBmi=np.asarray(iBmi)\n",
    "    \n",
    "    print(\"RLoss:\",RLoss)\n",
    "    #print(\"MAE Loss Forward:\",mseLossF)\n",
    "    #print(outputBMI)\n",
    "    return oBmi,iBmi,oAge,oPids#,oAttn,oAttnIdx\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evalFull(args, model):\n",
    "    model['g'].eval()\n",
    "    #model['d'].eval()\n",
    "    \n",
    "    RLoss=0\n",
    "    TBatches=0\n",
    "    \n",
    "    with T.autograd.no_grad():\n",
    "        files = 'data/val/'+GENDER+'/data'+G+'val.csv'\n",
    "        \n",
    "        drugFiles = 'data/val/'+GENDER+'/drug/drug'+G+'val.csv'\n",
    "    \n",
    "        maskFiles = 'data/val/'+GENDER+'/mask/mask'+G+'val.csv'\n",
    "        #print(files)\n",
    "        \n",
    "        dataset = CSVDataset(files, int(args.seq_len*BATCH_SIZE),1356100,args.seq_len,flag=0)\n",
    "        drugDataset = CSVDataset(drugFiles, int(args.seq_len*BATCH_SIZE),1356100, args.seq_len,flag=1)\n",
    "        maskDataset = CSVDataset(maskFiles, int(args.seq_len*BATCH_SIZE),1356100, args.seq_len,flag=1)\n",
    "\n",
    "        loader = DataLoader(dataset,batch_size=1,num_workers=0, shuffle=False)#number of times getitem is called in one iteration\n",
    "        drugLoader = DataLoader(drugDataset,batch_size=1,num_workers=0, shuffle=False)\n",
    "        maskLoader = DataLoader(maskDataset,batch_size=1,num_workers=0, shuffle=False)\n",
    "\n",
    "        \n",
    "        loss={}\n",
    "\n",
    "        #for every batch\n",
    "        for batch_idx, allData in enumerate(zip(loader, drugLoader, maskLoader)):\n",
    "            data,drug,mask=allData\n",
    "            pids=data[1]\n",
    "            data=data[0]\n",
    "            #print(data.shape)\n",
    "            #print(mask.shape)\n",
    "            if args.male:\n",
    "                age=data[:,:,:,1462]#V3Female-1448]#V3Male-1462]#V2-636]#203]\n",
    "                data=data[:,:,:,1:1458]#V3-Female-1:1444]#V3-Male-1:1458]#V2-1:636]#199]\n",
    "            elif args.female:\n",
    "                age=data[:,:,:,1448]#V3Female-1448]#V3Male-1462]#V2-636]#203]\n",
    "                data=data[:,:,:,1:1444]#V3-Female-1:1444]#V3-Male-1:1458]#V2-1:636]#199]\n",
    "            drug=drug[:,:,:,2:382]#V2-1:381]\n",
    "            target=mask[:,:,:,:4]\n",
    "            mask=mask[:,:,:,4]\n",
    "            \n",
    "            \n",
    "            #print(age.shape)\n",
    "            #print(data.shape)\n",
    "            #print(mask.shape)\n",
    "            #print(target.shape)\n",
    "            \n",
    "            age=age.squeeze()\n",
    "            data=data.squeeze()\n",
    "            pids=pids.squeeze()\n",
    "            drug=drug.squeeze()\n",
    "            mask=mask.squeeze()\n",
    "            target=target.squeeze()\n",
    "            \n",
    "            \n",
    "            if(args.fine_tune):\n",
    "                #======================Fine tuning with obs/pred window task=============================\n",
    "                pids=pids.view(data.shape[0],data.shape[1])\n",
    "            #             print(\"pids\",pids.shape)\n",
    "            #             print(\"pids\",pids[0])\n",
    "                testMask = mask.clone().detach()\n",
    "                y = target.clone().detach()\n",
    "                #print(\"ageOutside\",age[0])\n",
    "\n",
    "                 #------------remove last 5 timestamps------------------\n",
    "                #print(data[0:10,8:,653])\n",
    "            #             print(\"=====Initial Data===============\")\n",
    "            #             #print(\"data\",data[0,0,:])\n",
    "            #             print(\"mask\",mask[0])\n",
    "            #             print(\"testMask\",testMask[0])\n",
    "\n",
    "                for i in range(data.shape[0]):\n",
    "                    #total length\n",
    "                    j=40\n",
    "                    #prediction window\n",
    "                    k=args.predWin\n",
    "                    #remove values from pred window\n",
    "                    data[i,j-k:j,:]=0\n",
    "                    drug[i,j-k:j,:]=0\n",
    "                    mask[i,j-k:j]=0\n",
    "                    y[i,j-k:j,:]=0\n",
    "                    #zero values in observation window, so that it can be used to check loss in pred win only\n",
    "                    target[i,0:j-k,:]=0\n",
    "                    testMask[i,0:j-k]=0\n",
    "\n",
    "            #             print(\"=====test Data===============\")\n",
    "            #             #print(\"data\",data[0,0,:])\n",
    "            #             print(\"mask\",mask[0])\n",
    "            #             print(\"testMask\",testMask[0])\n",
    "\n",
    "            #             print(\"=====idxs Data===============\")\n",
    "                #check where obs win is empty\n",
    "                emptyIds=torch.sum(data.reshape(data.shape[0],-1),dim=1)\n",
    "            #             print(\"emptyIds\",emptyIds.shape)\n",
    "            #             print(\"emptyIds\",emptyIds)\n",
    "                idxs = torch.nonzero(emptyIds > 0)\n",
    "                idxs=idxs.squeeze()\n",
    "            #             print(\"idxs\",idxs.shape)\n",
    "                #get only data points that have atleast 1 entry in obs window\n",
    "                data=data[idxs]\n",
    "                drug=drug[idxs]\n",
    "                mask=mask[idxs]\n",
    "                y=y[idxs]\n",
    "                target=target[idxs]\n",
    "                testMask=testMask[idxs]\n",
    "                pids=pids[idxs]\n",
    "                age=age[idxs]\n",
    "\n",
    "            #             print(\"data\",data.shape)\n",
    "            #             print(\"drug\",drug.shape)\n",
    "            #             print(\"mask\",mask.shape)\n",
    "            #             print(\"target\",target.shape)\n",
    "            #             print(\"pids\",pids.shape)\n",
    "            #             print(\"testMask\",testMask.shape)\n",
    "            #             print(\"age\",age.shape)\n",
    "\n",
    "                #data=torch.cat((data,y),2)\n",
    "                y=y.cuda(0)\n",
    "                testMask=testMask.cuda(0)\n",
    "                #========================================================================================\n",
    "            \n",
    "            #data=torch.cat((data,target),2)\n",
    "\n",
    "            #------------E training------------------\n",
    "            data=data.cuda(0)\n",
    "            target=target.cuda(0)\n",
    "            age=age.cuda(0)\n",
    "            drug=drug.cuda(0)\n",
    "            mask=mask.cuda(0)\n",
    "            output = model['g'](data, drug, target, age, mask, args.train)\n",
    "\n",
    "            #------------R Loss------------------\n",
    "            #print(\"output\",output.shape)\n",
    "\n",
    "            output = output.permute(1,0,2)\n",
    "            #print(\"output\",output.shape)\n",
    "            output = output.reshape(-1,output.shape[2])\n",
    "\n",
    "            #print(\"output\",output.shape)\n",
    "            #print(\"target\",target.shape)\n",
    "            ##print(\"output\",output[0,0,:])\n",
    "            ##print(\"target\",target[0,0,:])\n",
    "            top1 = target.argmax(2)\n",
    "            \n",
    "            #print(\"top1\",top1.shape)\n",
    "            \n",
    "\n",
    "            mask=mask.view(-1)\n",
    "            top1=top1.view(-1)\n",
    "            if(args.fine_tune):\n",
    "                testMask=testMask.view(-1)\n",
    "                idxs = torch.nonzero(testMask == 1)\n",
    "            else:\n",
    "                idxs = torch.nonzero(mask == 1)\n",
    "                \n",
    "            #print(\"mask\",mask.shape)\n",
    "\n",
    "            \n",
    "            idxs=idxs.squeeze()\n",
    "            #print(\"idxs\",idxs.shape)\n",
    "\n",
    "            output = output[idxs,:]\n",
    "            top1 = top1[idxs]\n",
    "            #print(\"output\",output.shape)\n",
    "            #print(\"top1\",top1.shape)\n",
    "\n",
    "            ##print(\"output\",output)\n",
    "            ##print(\"top1\",top1)\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            RLoss = RLoss + loss(output, top1)\n",
    "            #print(\"loss\",RLoss)\n",
    "\n",
    "        TBatches=TBatches+batch_idx+1\n",
    "        #print(TBatches)\n",
    "    #print(TBatches)\n",
    "    RLoss = RLoss/TBatches\n",
    "    #print(\"===================================\")\n",
    "    print(\"Val R Loss:\",RLoss)\n",
    "#     print(\"Val G Loss:\",loss['g'])\n",
    "#     print(\"Val D Loss:\",DLoss/TBatches)\n",
    "    \n",
    "    return RLoss\n",
    "                \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def batch_run(model, data, pids, drug, mask, age, target, args, optimizer, epoch):\n",
    "    \n",
    "    rloss=0\n",
    "    dloss=0\n",
    "    #print(\"==============going to encoder=====================\")\n",
    "    loss={}\n",
    "    freeze_d=False\n",
    "    #age=age.unsqueeze(2)\n",
    "    ##print(\"age\",age[0,:,:])\n",
    "    #print(age.shape)\n",
    "    #print(data.shape)\n",
    "    #print(mask.shape)\n",
    "    #print(target.shape)\n",
    "    \n",
    "    if(args.fine_tune):\n",
    "        #======================Fine tuning with obs/pred window task=============================\n",
    "        pids=pids.view(data.shape[0],data.shape[1])\n",
    "    #             print(\"pids\",pids.shape)\n",
    "    #             print(\"pids\",pids[0])\n",
    "        testMask = mask.clone().detach()\n",
    "        y = target.clone().detach()\n",
    "        #print(\"ageOutside\",age[0])\n",
    "\n",
    "         #------------remove last 5 timestamps------------------\n",
    "        #print(data[0:10,8:,653])\n",
    "    #             print(\"=====Initial Data===============\")\n",
    "    #             #print(\"data\",data[0,0,:])\n",
    "    #             print(\"mask\",mask[0])\n",
    "    #             print(\"testMask\",testMask[0])\n",
    "\n",
    "        for i in range(data.shape[0]):\n",
    "            #total length\n",
    "            j=40\n",
    "            #prediction window\n",
    "            k=args.predWin\n",
    "            #remove values from pred window\n",
    "            data[i,j-k:j,:]=0\n",
    "            drug[i,j-k:j,:]=0\n",
    "            mask[i,j-k:j]=0\n",
    "            y[i,j-k:j,:]=0\n",
    "            #zero values in observation window, so that it can be used to check loss in pred win only\n",
    "            target[i,0:j-k,:]=0\n",
    "            testMask[i,0:j-k]=0\n",
    "\n",
    "    #             print(\"=====test Data===============\")\n",
    "    #             #print(\"data\",data[0,0,:])\n",
    "    #             print(\"mask\",mask[0])\n",
    "    #             print(\"testMask\",testMask[0])\n",
    "\n",
    "    #             print(\"=====idxs Data===============\")\n",
    "        #check where obs win is empty\n",
    "        emptyIds=torch.sum(data.reshape(data.shape[0],-1),dim=1)\n",
    "    #             print(\"emptyIds\",emptyIds.shape)\n",
    "    #             print(\"emptyIds\",emptyIds)\n",
    "        idxs = torch.nonzero(emptyIds > 0)\n",
    "        idxs=idxs.squeeze()\n",
    "    #             print(\"idxs\",idxs.shape)\n",
    "        #get only data points that have atleast 1 entry in obs window\n",
    "        data=data[idxs]\n",
    "        drug=drug[idxs]\n",
    "        mask=mask[idxs]\n",
    "        y=y[idxs]\n",
    "        target=target[idxs]\n",
    "        testMask=testMask[idxs]\n",
    "        pids=pids[idxs]\n",
    "        age=age[idxs]\n",
    "\n",
    "    #             print(\"data\",data.shape)\n",
    "    #             print(\"drug\",drug.shape)\n",
    "    #             print(\"mask\",mask.shape)\n",
    "    #             print(\"target\",target.shape)\n",
    "    #             print(\"pids\",pids.shape)\n",
    "    #             print(\"testMask\",testMask.shape)\n",
    "    #             print(\"age\",age.shape)\n",
    "\n",
    "        #data=torch.cat((data,y),2)\n",
    "        y=y.cuda(0)\n",
    "        testMask=testMask.cuda(0)\n",
    "        #========================================================================================\n",
    "    \n",
    "    data=data.cuda(0)\n",
    "    drug=drug.cuda(0)\n",
    "    target=target.cuda(0)\n",
    "    age=age.cuda(0)\n",
    "    mask=mask.cuda(0)\n",
    "    \n",
    "    #------------E training------------------\n",
    "    optimizer['g'].zero_grad()\n",
    "    output = model['g'](data, drug, target, age, mask, args.train)\n",
    "    \n",
    "    #print(\"==============Batch Over=============\")\n",
    "    #print(\"output\",output.shape)\n",
    "        \n",
    "    output = output.permute(1,0,2)\n",
    "    #print(\"output\",output.shape)\n",
    "    #print(\"output\",output[0,0,:])\n",
    "    out = output.argmax(2)\n",
    "    #print(\"out\",out.shape)\n",
    "    #print(\"out\",out[0,:])\n",
    "    output = output.reshape(-1,output.shape[2])\n",
    "    #print(\"output\",output.shape)\n",
    "    #print(\"target\",target.shape)\n",
    "    ##print(\"target\",target[0,0,:])\n",
    "    top1 = target.argmax(2)\n",
    "    #print(\"top1\",top1.shape)\n",
    "    #print(\"top1\",top1[0,:])\n",
    "    #print(\"mask\",mask.shape)\n",
    "    #print(\"mask\",mask[0,:])\n",
    "    #discriminator\n",
    "    #------------D training------------------\n",
    "    if  args.discriminator:\n",
    "        optimizer['d'].zero_grad()\n",
    "        mask=mask.float()\n",
    "        top1=top1.float()\n",
    "        out=out.float()\n",
    "        decodedOutput=out*(1-mask)+top1*(mask)\n",
    "        #print(\"decodedOutput\",decodedOutput.shape)\n",
    "        #print(\"decodedOutput\",decodedOutput[0,:])\n",
    "        lossDf = model['d'](decodedOutput, mask, direct=\"forward\")\n",
    "        lossDb = model['d'](decodedOutput, mask, direct=\"backward\")\n",
    "        #print(\"================Outside Discriminator=================\")\n",
    "        dloss=lossDf['loss_d']+lossDb['loss_d']\n",
    "        if (epoch%2==0):\n",
    "            dloss.backward(retain_graph=True)\n",
    "            optimizer['d'].step()\n",
    "            dloss=dloss.item()\n",
    "    \n",
    "    mask=mask.long()\n",
    "    top1=top1.long()\n",
    "    top1=top1.view(-1)\n",
    "    #print(\"top1\",top1.shape)\n",
    "    \n",
    "    mask=mask.view(-1)\n",
    "    \n",
    "    if(args.fine_tune):\n",
    "        testMask=testMask.view(-1)\n",
    "        idxs = torch.nonzero(testMask == 1)\n",
    "    else:\n",
    "        idxs = torch.nonzero(mask == 1)\n",
    "    idxs=idxs.squeeze()\n",
    "    #print(\"idxs\",idxs.shape)\n",
    "    #print(\"i m here\")\n",
    "    output = output[idxs,:]\n",
    "    top1 = top1[idxs]\n",
    "    #print(\"output\",output.shape)\n",
    "    #print(\"top1\",top1.shape)\n",
    "    \n",
    "    ##print(\"output\",output)\n",
    "    ##print(\"top1\",top1)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    rloss = loss(output, top1)\n",
    "    #print(\"loss\",rloss)\n",
    "    if  args.discriminator:\n",
    "        rloss1=rloss+lossDf['loss_g']+lossDb['loss_g']\n",
    "        rloss1.backward()\n",
    "    else:\n",
    "        rloss.backward()\n",
    "        \n",
    "    #------------E G training------------------\n",
    "    #optimizer['e'].zero_grad()\n",
    "    #optimizer['g'].zero_grad()\n",
    "    \n",
    "    #optimizer['e'].step()\n",
    "    optimizer['g'].step()\n",
    "    #print(\"i m here\")\n",
    "    if  args.discriminator:\n",
    "        return rloss,dloss\n",
    "    else:\n",
    "        return rloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc():\n",
    "    #discriminator\n",
    "    #------------D training------------------\n",
    "    if  args.discriminator:\n",
    "    #         #print(\"Auto\")\n",
    "        if args.noise:\n",
    "            #print(\"Noise\")\n",
    "            #------------Random Noise G training------------------\n",
    "            h_noise = T.empty([data.shape[0], 400]).uniform_() # random vector\n",
    "            z_noise=h_noise.repeat(1,args.seq_len).view(h_noise.shape[0],args.seq_len,-1)\n",
    "            ##print(\"Noise input\",z_noise.shape)\n",
    "            h_noise=T.unsqueeze(h_noise,0)\n",
    "            c_noise = T.empty([1, c_n.shape[1], c_n.shape[2]]).uniform_()\n",
    "            ##print(\"noise\",h_noise.shape,c_noise.shape)\n",
    "            noiseOutput = model['g'](z_noise,(h_noise,c_noise))\n",
    "            nLabels = model['d'](noiseOutput.detach(),flag=\"fake\")\n",
    "\n",
    "            rLabels = model['d'](data,flag=\"original\")\n",
    "            fLabels = model['d'](decodedOutput.detach(),flag=\"fake\")\n",
    "            loss['d'] = criterion['d'](rLabels,fLabels,nLabels)\n",
    "\n",
    "            noise_loss= -T.mean(nLabels)\n",
    "            #############################################################\n",
    "            #if No Noise\n",
    "            optimizer['d'].zero_grad()\n",
    "            decodedOutput=top1*(mask)+output*(1-mask)\n",
    "            lossDf = model['d'](decodedOutput, mask, direct=\"forward\")\n",
    "            lossDb = model['d'](decodedOutput, mask, direct=\"backward\")\n",
    "\n",
    "            ##print(rLabels.shape,y_real.shape)\n",
    "            #loss['d'] = F.binary_cross_entropy(rLabels, y_real) + 0.5*(F.binary_cross_entropy(fLabels, y_fake) + F.binary_cross_entropy(nLabels, y_fake))\n",
    "            loss['d']=lossDf['loss_d']+lossDb['loss_d']\n",
    "            DLoss=DLoss+loss['d'].item()\n",
    "\n",
    "            #if not freeze_d:\n",
    "            ##print(loss['d'])\n",
    "            #optimizer['d'].zero_grad()\n",
    "            loss['d'].backward(retain_graph=True)\n",
    "            optimizer['d'].step()\n",
    "\n",
    "            loss['gd']= lossDf['loss_g']+lossDb['loss_g']\n",
    "            GLoss=GLoss+loss['gd'].item()\n",
    "            loss['g']=loss['g']+loss['gd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBmi(outBmi, inBmi, age):\n",
    "    \n",
    "    outBmi = outBmi.cpu().detach().numpy()\n",
    "    inBmi = inBmi.cpu().detach().numpy()\n",
    "    testMask = testMask.cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    outBmi=outBmi[np.nonzero(testMask)]\n",
    "    inBmi=inBmi[np.nonzero(testMask)]\n",
    "    \n",
    "    \n",
    "    return outBmi,inBmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def run_epoch(args, model, optimizer):\n",
    "    ''' Run a single epoch\n",
    "    '''\n",
    "    \n",
    "    decodedOutput=[]\n",
    "    trainLoss=[]\n",
    "    trainDLoss=[]\n",
    "    valLoss=[]\n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(args,patience=args.patience, verbose=True)\n",
    "    if args.resume_training:\n",
    "        early_stopping(3.246886, model, optimizer, save_path)\n",
    "    #for evrey epoch\n",
    "    for epoch in range(args.num_epochs):\n",
    "        model['g'].train()\n",
    "        if  args.discriminator:\n",
    "            model['d'].train()\n",
    "        \n",
    "        ##print(model['e'])\n",
    "        ##print(model['g'])\n",
    "    \n",
    "        #Running Losses\n",
    "        RLoss=0\n",
    "        DLoss=0\n",
    "#         GLoss=0\n",
    "        TBatches=0  \n",
    "        #output=[]\n",
    "        print(\"=============EPOCH================= \",epoch)\n",
    "        freeze_d=False\n",
    "        #if epoch<=args.g_pretraining_epochs:\n",
    "            #freeze_d=True\n",
    "       \n",
    "        path = 'data/train/'+GENDER+'/'\n",
    "        files = list(map(lambda x : path + x, (filter(lambda x : x.endswith(\"csv\"), os.listdir(path)))))\n",
    "        \n",
    "        drugPath = 'data/train/'+GENDER+'/drug/'\n",
    "        drugFiles = list(map(lambda x : drugPath + x, (filter(lambda x : x.endswith(\"csv\"), os.listdir(drugPath)))))\n",
    "        \n",
    "        maskPath = 'data/train/'+GENDER+'/mask/'\n",
    "        maskFiles = list(map(lambda x : maskPath + x, (filter(lambda x : x.endswith(\"csv\"), os.listdir(maskPath)))))\n",
    "        \n",
    "        ids=range(0,len(files))\n",
    "        for i in ids:\n",
    "            #print(files[i])\n",
    "            dataset = CSVDataset(files[i], int(args.seq_len*BATCH_SIZE),1356100,args.seq_len,flag=0)\n",
    "            drugDataset = CSVDataset(drugFiles[i], int(args.seq_len*BATCH_SIZE),1356100, args.seq_len,flag=1)\n",
    "            maskDataset = CSVDataset(maskFiles[i], int(args.seq_len*BATCH_SIZE),1356100, args.seq_len,flag=1)\n",
    "\n",
    "            loader = DataLoader(dataset,batch_size=1,num_workers=0, shuffle=False)#number of times getitem is called in one iteration\n",
    "            drugLoader = DataLoader(drugDataset,batch_size=1,num_workers=0, shuffle=False)\n",
    "            maskLoader = DataLoader(maskDataset,batch_size=1,num_workers=0, shuffle=False)\n",
    "\n",
    "            ##print(files)\n",
    "            #for every batch\n",
    "            for batch_idx, allData in enumerate(zip(loader, drugLoader, maskLoader)):\n",
    "                #bmi_norm=dataset.bmi_norm\n",
    "                ##print('batch: {}'.format(batch_idx))\n",
    "                data,drug,mask=allData\n",
    "                pids=data[1]\n",
    "                data=data[0]\n",
    "                #print(data.shape)\n",
    "                #print(mask.shape)\n",
    "                #print(\"drug\",drug.shape)\n",
    "                if args.male:\n",
    "                    age=data[:,:,:,1462]#V3Female-1448]#V3Male-1462]#V2-636]#203]\n",
    "                    data=data[:,:,:,1:1458]#V3-Female-1:1444]#V3-Male-1:1458]#V2-1:636]#199]\n",
    "                elif args.female:\n",
    "                    age=data[:,:,:,1448]#V3Female-1448]#V3Male-1462]#V2-636]#203]\n",
    "                    data=data[:,:,:,1:1444]#V3-Female-1:1444]#V3-Male-1:1458]#V2-1:636]#199]\n",
    "                drug=drug[:,:,:,2:382]#V2-1:381]\n",
    "                target=mask[:,:,:,:4]\n",
    "                mask=mask[:,:,:,4]\n",
    "\n",
    "                #print(age.shape)\n",
    "                #print(data.shape)\n",
    "                #print(mask.shape)\n",
    "                #print(target.shape)\n",
    "\n",
    "                age=age.squeeze()\n",
    "                data=data.squeeze()\n",
    "                pids=pids.squeeze()\n",
    "                drug=drug.squeeze()\n",
    "                mask=mask.squeeze()\n",
    "                target=target.squeeze()\n",
    "                \n",
    "               # data=torch.cat((data,target),2)\n",
    "\n",
    "                #print(\"age\",age[0])\n",
    "                #print(\"data\",data.shape)\n",
    "                #print(\"mask\",mask[0,:])\n",
    "                #print(\"target\",target[0,:,:])\n",
    "\n",
    "                ##print(\"age\",age[0,:])\n",
    "                if  args.discriminator:\n",
    "                    rloss,dloss=batch_run(model, data, pids, drug, mask, age, target, args, optimizer, epoch)\n",
    "                    #print(\"Batch Over\")\n",
    "                    RLoss = RLoss + rloss\n",
    "                    DLoss = DLoss + dloss\n",
    "                    #print(\"RLoss\",RLoss)\n",
    "                    #print(\"DLoss\",DLoss)\n",
    "                else:\n",
    "                    rloss=batch_run(model, data, pids, drug, mask, age, target, args, optimizer, epoch)\n",
    "                    RLoss = RLoss + rloss\n",
    "\n",
    "                T.cuda.empty_cache()\n",
    "                #paramsE=list(model['e'].parameters())\n",
    "                #paramsG=list(model['g'].parameters())\n",
    "                ##print(\"AFTER PARAM\",paramsE[0][20],paramsG[8][0][0])   \n",
    "\n",
    "            TBatches=TBatches+batch_idx+1\n",
    "        RLoss=RLoss/TBatches\n",
    "        DLoss=DLoss/TBatches\n",
    "#         GLoss=GLoss/TBatches   \n",
    "        print(\"Train Loss\",RLoss)\n",
    "        if  args.discriminator:\n",
    "            print(\"Disc Loss\",DLoss)\n",
    "            trainDLoss.append(DLoss)\n",
    "        trainLoss.append(RLoss)\n",
    "\n",
    "       \n",
    "        valid_loss = run_evalFull(args, model)\n",
    "        \n",
    "        valLoss.append(valid_loss)\n",
    "\n",
    "        #print(\"epoch:\", epoch, \"loss_R:\", \"%.4f\"%RLoss, \"loss_G:\", \"%.4f\"%GLoss, \"loss_D:\", \"%.4f\"%DLoss)\n",
    "        #if epoch<1 or epoch >5:\n",
    "        valid_loss=valid_loss.cpu()\n",
    "        if not (np.isnan(valid_loss)):\n",
    "            early_stopping(valid_loss, model, optimizer, save_path)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        #plot_grad_flow(model['e'].named_parameters())\n",
    "        #plot_grad_flow(model['g'].named_parameters())\n",
    "        #plot_grad_flow(model['d'].named_parameters())\n",
    "    return trainLoss, valLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    ''' Training sequence\n",
    "    '''\n",
    "    train_on_gpu = T.cuda.is_available()\n",
    "    if train_on_gpu:\n",
    "        print('Training on GPU.')\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    else:\n",
    "        print('No GPU available, training on CPU.')\n",
    "        \n",
    "    #Create Models\n",
    "    attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "    enc = Encoder(INPUT_DIM, DRUG_DIM, AGE_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, AGE_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "    if  args.discriminator:\n",
    "        model = {\n",
    "            'g' : Seq2Seq(enc, dec),\n",
    "            'd' : Discriminator(MAX_SEQ_LEN, D_HID_SIZE)\n",
    "        }\n",
    "    else:\n",
    "        model = {'g' : Seq2Seq(enc, dec)}\n",
    "\n",
    "    if  args.discriminator:\n",
    "        optimizer = {\n",
    "            'g': optim.Adam(model['g'].parameters(), lr=1e-3),\n",
    "            'd': optim.Adam(model['d'].parameters(), lr=1e-3)\n",
    "        }\n",
    "    else:\n",
    "        optimizer = {\n",
    "        'g': optim.Adam(model['g'].parameters(), lr=1e-2)\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model['g'].cuda(0)\n",
    "        if  args.discriminator:\n",
    "            model['d'].cuda(0)\n",
    "        \n",
    "    if args.resume_training:\n",
    "        checkpoint = T.load(save_path)\n",
    "        model['g'].load_state_dict(checkpoint['G_model'])\n",
    "        if  args.discriminator:\n",
    "            model['d'].load_state_dict(checkpoint['D_model'])\n",
    "        optimizer['g'].load_state_dict(checkpoint['G_trainer'])\n",
    "        if  args.discriminator:\n",
    "            optimizer['d'].load_state_dict(checkpoint['D_trainer'])\n",
    "        #Save Updated Model\n",
    "        \n",
    "        trainloss, valLoss = run_epoch(args, model, optimizer) \n",
    "        \n",
    "        return trainloss, valLoss\n",
    "    \n",
    "    elif args.train:\n",
    "        print(\"================PRE-TRAINING===================\")\n",
    "        trainloss, valLoss = run_epoch(args, model, optimizer) \n",
    "        \n",
    "        return trainloss, valLoss\n",
    " \n",
    "    elif args.evalPred:\n",
    "        #load Model\n",
    "        checkpoint = T.load(save_path)\n",
    "        model['g'].load_state_dict(checkpoint['G_model'])\n",
    "        if  args.discriminator:\n",
    "            model['d'].load_state_dict(checkpoint['D_model'])\n",
    "        optimizer['g'].load_state_dict(checkpoint['G_trainer'])\n",
    "        if  args.discriminator:\n",
    "            optimizer['d'].load_state_dict(checkpoint['D_trainer'])\n",
    "        #oBmi, iBmi, oAge, pids, oAttn,oAttnIdx = pred_test(args, model)\n",
    "        oBmi, iBmi, oAge, pids = pred_test(args, model)\n",
    "        \n",
    "        return oBmi, iBmi, oAge, pids#, oAttn, oAttnIdx\n",
    "    \n",
    "    #'epoch': epoch + 1,\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n",
      "================PRE-TRAINING===================\n",
      "=============EPOCH=================  0\n",
      "Train Loss tensor(0.9226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.3190727031694285\n",
      "Val R Loss: tensor(0.8144, device='cuda:0')\n",
      "Validation loss decreased (inf --> 0.814427).  Saving model ...\n",
      "=============EPOCH=================  1\n",
      "Train Loss tensor(0.7328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.7008, device='cuda:0')\n",
      "Validation loss decreased (0.814427 --> 0.700810).  Saving model ...\n",
      "=============EPOCH=================  2\n",
      "Train Loss tensor(0.6790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.288071586891956\n",
      "Val R Loss: tensor(0.6771, device='cuda:0')\n",
      "Validation loss decreased (0.700810 --> 0.677093).  Saving model ...\n",
      "=============EPOCH=================  3\n",
      "Train Loss tensor(0.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6666, device='cuda:0')\n",
      "Validation loss decreased (0.677093 --> 0.666605).  Saving model ...\n",
      "=============EPOCH=================  4\n",
      "Train Loss tensor(0.6370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2850268590576657\n",
      "Val R Loss: tensor(0.6532, device='cuda:0')\n",
      "Validation loss decreased (0.666605 --> 0.653198).  Saving model ...\n",
      "=============EPOCH=================  5\n",
      "Train Loss tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6380, device='cuda:0')\n",
      "Validation loss decreased (0.653198 --> 0.637953).  Saving model ...\n",
      "=============EPOCH=================  6\n",
      "Train Loss tensor(0.6149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2853469124109922\n",
      "Val R Loss: tensor(0.6380, device='cuda:0')\n",
      "Validation loss decreased (0.637953 --> 0.637963).  Saving model ...\n",
      "=============EPOCH=================  7\n",
      "Train Loss tensor(0.6076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6470, device='cuda:0')\n",
      "Validation loss decreased (0.637953 --> 0.647044).  Saving model ...\n",
      "=============EPOCH=================  8\n",
      "Train Loss tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.284078718074219\n",
      "Val R Loss: tensor(0.6404, device='cuda:0')\n",
      "Validation loss decreased (0.637953 --> 0.640392).  Saving model ...\n",
      "=============EPOCH=================  9\n",
      "Train Loss tensor(0.5952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6306, device='cuda:0')\n",
      "Validation loss decreased (0.637953 --> 0.630584).  Saving model ...\n",
      "=============EPOCH=================  10\n",
      "Train Loss tensor(0.5923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.282683994239295\n",
      "Val R Loss: tensor(0.6244, device='cuda:0')\n",
      "Validation loss decreased (0.630584 --> 0.624444).  Saving model ...\n",
      "=============EPOCH=================  11\n",
      "Train Loss tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6217, device='cuda:0')\n",
      "Validation loss decreased (0.624444 --> 0.621654).  Saving model ...\n",
      "=============EPOCH=================  12\n",
      "Train Loss tensor(0.5840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.281251516022025\n",
      "Val R Loss: tensor(0.6106, device='cuda:0')\n",
      "Validation loss decreased (0.621654 --> 0.610581).  Saving model ...\n",
      "=============EPOCH=================  13\n",
      "Train Loss tensor(0.5806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6153, device='cuda:0')\n",
      "Validation loss decreased (0.610581 --> 0.615343).  Saving model ...\n",
      "=============EPOCH=================  14\n",
      "Train Loss tensor(0.5787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2792357623366502\n",
      "Val R Loss: tensor(0.6065, device='cuda:0')\n",
      "Validation loss decreased (0.610581 --> 0.606450).  Saving model ...\n",
      "=============EPOCH=================  15\n",
      "Train Loss tensor(0.5759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6133, device='cuda:0')\n",
      "Validation loss decreased (0.606450 --> 0.613297).  Saving model ...\n",
      "=============EPOCH=================  16\n",
      "Train Loss tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2779186306909622\n",
      "Val R Loss: tensor(0.6087, device='cuda:0')\n",
      "Validation loss decreased (0.606450 --> 0.608725).  Saving model ...\n",
      "=============EPOCH=================  17\n",
      "Train Loss tensor(0.5705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6089, device='cuda:0')\n",
      "Validation loss decreased (0.606450 --> 0.608852).  Saving model ...\n",
      "=============EPOCH=================  18\n",
      "Train Loss tensor(0.5678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2768611116038615\n",
      "Val R Loss: tensor(0.6171, device='cuda:0')\n",
      "EarlyStopping counter: 1 out of 30\n",
      "=============EPOCH=================  19\n",
      "Train Loss tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6214, device='cuda:0')\n",
      "EarlyStopping counter: 2 out of 30\n",
      "=============EPOCH=================  20\n",
      "Train Loss tensor(0.5653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.275654724545698\n",
      "Val R Loss: tensor(0.6172, device='cuda:0')\n",
      "EarlyStopping counter: 3 out of 30\n",
      "=============EPOCH=================  21\n",
      "Train Loss tensor(0.5628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6205, device='cuda:0')\n",
      "EarlyStopping counter: 4 out of 30\n",
      "=============EPOCH=================  22\n",
      "Train Loss tensor(0.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2756364762572434\n",
      "Val R Loss: tensor(0.6215, device='cuda:0')\n",
      "EarlyStopping counter: 5 out of 30\n",
      "=============EPOCH=================  23\n",
      "Train Loss tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6136, device='cuda:0')\n",
      "Validation loss decreased (0.606450 --> 0.613589).  Saving model ...\n",
      "=============EPOCH=================  24\n",
      "Train Loss tensor(0.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2748675965588843\n",
      "Val R Loss: tensor(0.6216, device='cuda:0')\n",
      "EarlyStopping counter: 1 out of 30\n",
      "=============EPOCH=================  25\n",
      "Train Loss tensor(0.5542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6326, device='cuda:0')\n",
      "EarlyStopping counter: 2 out of 30\n",
      "=============EPOCH=================  26\n",
      "Train Loss tensor(0.5524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2737940250774153\n",
      "Val R Loss: tensor(0.6223, device='cuda:0')\n",
      "EarlyStopping counter: 3 out of 30\n",
      "=============EPOCH=================  27\n",
      "Train Loss tensor(0.5487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6311, device='cuda:0')\n",
      "EarlyStopping counter: 4 out of 30\n",
      "=============EPOCH=================  28\n",
      "Train Loss tensor(0.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2740129754737073\n",
      "Val R Loss: tensor(0.6278, device='cuda:0')\n",
      "EarlyStopping counter: 5 out of 30\n",
      "=============EPOCH=================  29\n",
      "Train Loss tensor(0.5458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6344, device='cuda:0')\n",
      "EarlyStopping counter: 6 out of 30\n",
      "=============EPOCH=================  30\n",
      "Train Loss tensor(0.5437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2735943381440935\n",
      "Val R Loss: tensor(0.6303, device='cuda:0')\n",
      "EarlyStopping counter: 7 out of 30\n",
      "=============EPOCH=================  31\n",
      "Train Loss tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6304, device='cuda:0')\n",
      "EarlyStopping counter: 8 out of 30\n",
      "=============EPOCH=================  32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss tensor(0.5394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2730883094531487\n",
      "Val R Loss: tensor(0.6408, device='cuda:0')\n",
      "EarlyStopping counter: 9 out of 30\n",
      "=============EPOCH=================  33\n",
      "Train Loss tensor(0.5368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6447, device='cuda:0')\n",
      "EarlyStopping counter: 10 out of 30\n",
      "=============EPOCH=================  34\n",
      "Train Loss tensor(0.5348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.27293061114874\n",
      "Val R Loss: tensor(0.6432, device='cuda:0')\n",
      "EarlyStopping counter: 11 out of 30\n",
      "=============EPOCH=================  35\n",
      "Train Loss tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6444, device='cuda:0')\n",
      "EarlyStopping counter: 12 out of 30\n",
      "=============EPOCH=================  36\n",
      "Train Loss tensor(0.5287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2725786354011024\n",
      "Val R Loss: tensor(0.6537, device='cuda:0')\n",
      "EarlyStopping counter: 13 out of 30\n",
      "=============EPOCH=================  37\n",
      "Train Loss tensor(0.5277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6485, device='cuda:0')\n",
      "EarlyStopping counter: 14 out of 30\n",
      "=============EPOCH=================  38\n",
      "Train Loss tensor(0.5241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2716911285589103\n",
      "Val R Loss: tensor(0.6522, device='cuda:0')\n",
      "EarlyStopping counter: 15 out of 30\n",
      "=============EPOCH=================  39\n",
      "Train Loss tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6619, device='cuda:0')\n",
      "EarlyStopping counter: 16 out of 30\n",
      "=============EPOCH=================  40\n",
      "Train Loss tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.271878269451667\n",
      "Val R Loss: tensor(0.6646, device='cuda:0')\n",
      "EarlyStopping counter: 17 out of 30\n",
      "=============EPOCH=================  41\n",
      "Train Loss tensor(0.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6613, device='cuda:0')\n",
      "EarlyStopping counter: 18 out of 30\n",
      "=============EPOCH=================  42\n",
      "Train Loss tensor(0.5148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2716513674166514\n",
      "Val R Loss: tensor(0.6741, device='cuda:0')\n",
      "EarlyStopping counter: 19 out of 30\n",
      "=============EPOCH=================  43\n",
      "Train Loss tensor(0.5114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6845, device='cuda:0')\n",
      "EarlyStopping counter: 20 out of 30\n",
      "=============EPOCH=================  44\n",
      "Train Loss tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.271898406975682\n",
      "Val R Loss: tensor(0.6871, device='cuda:0')\n",
      "EarlyStopping counter: 21 out of 30\n",
      "=============EPOCH=================  45\n",
      "Train Loss tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6974, device='cuda:0')\n",
      "EarlyStopping counter: 22 out of 30\n",
      "=============EPOCH=================  46\n",
      "Train Loss tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2709394899779412\n",
      "Val R Loss: tensor(0.6867, device='cuda:0')\n",
      "EarlyStopping counter: 23 out of 30\n",
      "=============EPOCH=================  47\n",
      "Train Loss tensor(0.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6994, device='cuda:0')\n",
      "EarlyStopping counter: 24 out of 30\n",
      "=============EPOCH=================  48\n",
      "Train Loss tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2709686747709348\n",
      "Val R Loss: tensor(0.6853, device='cuda:0')\n",
      "EarlyStopping counter: 25 out of 30\n",
      "=============EPOCH=================  49\n",
      "Train Loss tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.6964, device='cuda:0')\n",
      "EarlyStopping counter: 26 out of 30\n",
      "=============EPOCH=================  50\n",
      "Train Loss tensor(0.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2712039399905255\n",
      "Val R Loss: tensor(0.7045, device='cuda:0')\n",
      "EarlyStopping counter: 27 out of 30\n",
      "=============EPOCH=================  51\n",
      "Train Loss tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.7090, device='cuda:0')\n",
      "EarlyStopping counter: 28 out of 30\n",
      "=============EPOCH=================  52\n",
      "Train Loss tensor(0.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss 1.2705023777358524\n",
      "Val R Loss: tensor(0.7178, device='cuda:0')\n",
      "EarlyStopping counter: 29 out of 30\n",
      "=============EPOCH=================  53\n",
      "Train Loss tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Disc Loss tensor(1.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val R Loss: tensor(0.7011, device='cuda:0')\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "#oBmi, iBmi, oAge, pids = main(ARGS)\n",
    "trainloss, valLoss = main(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if ARGS.predWin==12:\n",
    "    OBS='7'\n",
    "elif ARGS.predWin==20:\n",
    "    OBS='5'\n",
    "elif ARGS.predWin==28:\n",
    "    OBS='3'\n",
    "\n",
    "#with open('data/saved_models/'+GENDER+'/pre/disc/full/trainloss3', 'wb') as fp:\n",
    "#       pickle.dump(trainloss, fp)\n",
    "    \n",
    "#with open('data/saved_models/'+GENDER+'/pre/disc/full/valLoss3', 'wb') as fp:\n",
    "#       pickle.dump(valLoss, fp)\n",
    "\n",
    "        \n",
    "#with open('data/saved_models/'+GENDER+'/pre/disc/full/'+OBS+'/oBmi3', 'wb') as fp:\n",
    "#      pickle.dump(oBmi, fp)\n",
    "    \n",
    "#with open('data/saved_models/'+GENDER+'/pre/disc/full/'+OBS+'/iBmi3', 'wb') as fp:\n",
    "#      pickle.dump(iBmi, fp)\n",
    "\n",
    "#with open('data/saved_models/'+GENDER+'/pre/disc/full/'+OBS+'/oAge3', 'wb') as fp:\n",
    "#      pickle.dump(oAge, fp)\n",
    "#with open('data/saved_models/'+GENDER+'/pre/disc/full/'+OBS+'/pids3', 'wb') as fp:\n",
    "#      pickle.dump(pids, fp)\n",
    "\n",
    "# with open('data/saved_models/'+GENDER+'/pre/disc/full/'+OBS+'/attn2/attn', 'wb') as fp:\n",
    "#     pickle.dump(oAttn, fp)\n",
    "\n",
    "# with open('data/saved_models/'+GENDER+'/pre/disc/full/'+OBS+'/attn2/oAttnIdx', 'wb') as fp:\n",
    "#     pickle.dump(oAttnIdx, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_tensor = torch.rand((2, 5, 4, 7))\n",
    "# rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_tensor = rand_tensor.sum(2)\n",
    "# rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.Sigmoid()\n",
    "# loss = nn.BCELoss()\n",
    "# input = torch.randn(3, requires_grad=True)\n",
    "# target = torch.empty(3).random_(2)\n",
    "# output = loss(m(input), target)\n",
    "# #>>> output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Atena] *",
   "language": "python",
   "name": "conda-env-Atena-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
